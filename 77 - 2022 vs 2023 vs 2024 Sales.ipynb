{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f56879cb-853f-4a14-9a54-47d1d5d63ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are tasked with analyzing the sales growth of products over the years 2022, 2023, and 2024. Your goal is to identify months where the sales for a product have consistently increased from 2022 to 2023 and from 2023 to 2024.\n",
    "Your task is to write an SQL query to generate a report that includes the sales for each product at the month level for the years 2022, 2023, and 2024. However, you should only include product and months combination where the sales have consistently increased from 2022 to 2023 and from 2023 to 2024, display the output in ascending order of product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3224ec5-4459-464b-889d-46c751dcaa83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"OrdersTable\").getOrCreate()\n",
    "\n",
    "# Define schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"order_date\", StringType(), True),\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"sales\", IntegerType(), True)\n",
    "])\n",
    "data=[(1001, 101, \"2022-01-01\", 1, 90),\n",
    "    (1002, 102, \"2022-01-03\", 2, 75),\n",
    "    (1003, 103, \"2022-01-05\", 3, 90),\n",
    "    (1004, 104, \"2022-01-08\", 1, 50),\n",
    "    (1005, 105, \"2022-01-10\", 2, 150),\n",
    "    (1006, 106, \"2022-02-02\", 3, 30),\n",
    "    (1007, 107, \"2022-02-05\", 1, 180),\n",
    "    (1008, 108, \"2022-02-08\", 2, 75),\n",
    "    (1009, 109, \"2022-02-12\", 3, 60),\n",
    "    (1010, 110, \"2022-02-15\", 1, 100),\n",
    "    (1011, 111, \"2022-03-01\", 2, 75),\n",
    "    (1012, 112, \"2022-03-03\", 3, 60),\n",
    "    (2001, 113, \"2023-01-02\", 1, 95),\n",
    "    (2002, 114, \"2023-01-04\", 2, 80),\n",
    "    (2003, 115, \"2023-01-06\", 3, 85),\n",
    "    (2004, 116, \"2023-01-09\", 1, 55),\n",
    "    (2005, 117, \"2023-01-11\", 2, 160),\n",
    "    (2006, 118, \"2023-02-03\", 3, 35),\n",
    "    (2007, 119, \"2023-02-06\", 1, 185),\n",
    "    (2008, 120, \"2023-02-09\", 2, 70),\n",
    "    (2009, 121, \"2023-02-13\", 3, 65),\n",
    "    (2010, 122, \"2023-02-16\", 1, 105),\n",
    "    (2011, 123, \"2023-03-02\", 2, 80),\n",
    "    (2012, 124, \"2023-03-04\", 3, 65),\n",
    "    (3001, 125, \"2024-01-03\", 1, 100),\n",
    "    (3002, 126, \"2024-01-05\", 2, 85),\n",
    "    (3003, 127, \"2024-01-07\", 3, 95),\n",
    "    (3004, 128, \"2024-01-10\", 1, 60),\n",
    "    (3005, 129, \"2024-01-12\", 2, 170),\n",
    "    (3006, 130, \"2024-02-04\", 3, 40),\n",
    "    (3007, 131, \"2024-02-07\", 1, 190),\n",
    "    (3008, 132, \"2024-02-10\", 2, 85),\n",
    "    (3009, 133, \"2024-02-14\", 3, 70),\n",
    "    (3010, 134, \"2024-02-17\", 1, 110),\n",
    "    (3011, 135, \"2024-03-03\", 2, 85),\n",
    "    (3012, 136, \"2024-03-05\", 3, 70)\n",
    "]\n",
    "order_df=spark.createDataFrame(data,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04f17f30-6d57-4762-b1d7-8371cda7ea79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#converting the string to date \n",
    "order_df=order_df.withColumn(\"order_date\",col(\"order_date\").cast(\"date\"))\n",
    "\n",
    "#extracting the year and month from date\n",
    "order_df=order_df.withColumn(\"order_year\",year(col(\"order_date\")))\n",
    "order_df=order_df.withColumn(\"order_month\",month(col(\"order_date\")))\n",
    "\n",
    "#group by product_id,order_year,order_month \n",
    "order_df=order_df.groupBy(col(\"product_id\"),col(\"order_year\"),col(\"order_month\")).agg(sum(\"sales\").alias(\"Total_Sales\"))\n",
    "\n",
    "order_df = order_df.groupBy(\"product_id\", \"order_month\").agg(\n",
    "sum(when(col(\"order_year\") == 2022, col(\"Total_Sales\")).otherwise(0)).alias(\"2022_Sales\"),\n",
    "sum(when(col(\"order_year\") == 2023, col(\"Total_Sales\")).otherwise(0)).alias(\"2023_Sales\"),\n",
    "sum(when(col(\"order_year\") == 2024, col(\"Total_Sales\")).otherwise(0)).alias(\"2024_Sales\")\n",
    ")\n",
    "# consistently increased from 2022 to 2023 and from 2023 to 2024 and sort the product_id by ascending order\n",
    "order_df=order_df.filter((col(\"2023_Sales\") > col(\"2022_Sales\")) & (col(\"2024_Sales\") > col(\"2023_Sales\"))) \\\n",
    "    .orderBy(col(\"product_id\").asc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6bd01a0-3208-4493-a36f-e09047ce0ca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0619d1db-7885-44e4-9bf6-06ec918b084a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "77 - 2022 vs 2023 vs 2024 Sales",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

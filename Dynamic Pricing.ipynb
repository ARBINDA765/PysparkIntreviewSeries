{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03c02c21-ce78-426e-981f-eb1d8187f396",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You are given a products table where a new row is inserted every time the price of a product changes. Additionally, there is a transaction table containing details such as order_date and product_id for each order.\n",
    "\n",
    "Write an SQL query to calculate the total sales value for each product, considering the cost of the product at the time of the order date, display the output in ascending order of the product_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b8cdff0-85c3-4d17-b155-d24ab83614fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "from pyspark.sql.window import *\n",
    "spark=SparkSession.builder.appName(\"DynamicPricing\").getOrCreate()\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField,IntegerType,StringType,DateType\n",
    "products_schema=StructType(\n",
    "    [\n",
    "        StructField(\"product_id\",IntegerType(),True),\n",
    "        StructField(\"price_date\",DateType(),True),\n",
    "        StructField(\"price\",IntegerType(),True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "products_data = [\n",
    "    (100, datetime.strptime('2024-01-01', '%Y-%m-%d'), 150),\n",
    "    (100, datetime.strptime('2024-01-21', '%Y-%m-%d'), 170),\n",
    "    (100, datetime.strptime('2024-02-01', '%Y-%m-%d'), 190),\n",
    "    (101, datetime.strptime('2024-01-01', '%Y-%m-%d'), 1000),\n",
    "    (101, datetime.strptime('2024-01-27', '%Y-%m-%d'), 1200),\n",
    "    (101, datetime.strptime('2024-02-05', '%Y-%m-%d'), 1250)\n",
    "]\n",
    "\n",
    "product_df=spark.createDataFrame(schema=products_schema,data=products_data)\n",
    "\n",
    "order_schema=StructType(\n",
    "    [\n",
    "        StructField(\"order_id\",IntegerType(),True),\n",
    "        StructField(\"order_date\",DateType(),True),\n",
    "        StructField(\"product_id\",IntegerType(),True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "orders_data = [\n",
    "    (1, datetime.strptime('2024-01-05', '%Y-%m-%d'), 100),\n",
    "    (2, datetime.strptime('2024-01-21', '%Y-%m-%d'), 100),\n",
    "    (3, datetime.strptime('2024-02-20', '%Y-%m-%d'), 100),\n",
    "    (4, datetime.strptime('2024-01-07', '%Y-%m-%d'), 101),\n",
    "    (5, datetime.strptime('2024-02-04', '%Y-%m-%d'), 101),\n",
    "    (6, datetime.strptime('2024-02-05', '%Y-%m-%d'), 101)\n",
    "]\n",
    "\n",
    "orders_df=spark.createDataFrame(schema=order_schema,data=orders_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b928a44b-6cab-49fa-bef2-a88087fd5eea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n|product_id|total_sales|\n+----------+-----------+\n|       100|        510|\n|       101|       3450|\n+----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by 'product_id' and 'price_date'\n",
    "product_df=product_df.orderBy(col('product_id'),col('price_date'))\n",
    "\n",
    "# Create a lead column for 'price_date'\n",
    "window_spec=Window.partitionBy('product_id').orderBy('price_date')\n",
    "product_df=product_df.withColumn('lead_price_date',lead('price_date',1).over(window_spec))\n",
    "# Subtract 1 day from 'lead_price_date'\n",
    "product_df=product_df.withColumn(\"lead_price_date\",date_sub(\"lead_price_date\",1))\n",
    "\n",
    "\n",
    "# Fill null values in 'lead_price_date' with '2222-12-30'\n",
    "product_df=product_df.fillna({\"lead_price_date\":'2222-12-30'})\n",
    "\n",
    "# Merge with 'orders_df' on 'product_id'\n",
    "merged_df=product_df.join(orders_df,on=\"product_id\",how=\"inner\")\n",
    "\n",
    "merged_df = merged_df.filter(\n",
    "    (to_date('order_date') >= to_date('price_date')) &\n",
    "    (to_date('order_date') <= to_date('lead_price_date'))\n",
    ")\n",
    "# Calculate the total sales per product_id\n",
    "final_df = merged_df.groupBy('product_id').agg(sum('price').alias('total_sales'))\n",
    "\n",
    "# Sort the final DataFrame by 'product_id'\n",
    "final_df = final_df.orderBy('product_id')\n",
    "\n",
    "# Display the final DataFrame\n",
    "final_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6159c4b-3baa-4fbc-8ac4-2a221ae22a81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+---------------+--------+----------+\n|product_id|price_date|price|lead_price_date|order_id|order_date|\n+----------+----------+-----+---------------+--------+----------+\n|       100|2024-01-01|  150|     2024-01-20|       1|2024-01-05|\n|       100|2024-01-21|  170|     2024-01-31|       2|2024-01-21|\n|       100|2024-02-01|  190|     2222-12-30|       3|2024-02-20|\n|       101|2024-01-01| 1000|     2024-01-26|       4|2024-01-07|\n|       101|2024-01-27| 1200|     2024-02-04|       5|2024-02-04|\n|       101|2024-02-05| 1250|     2222-12-30|       6|2024-02-05|\n+----------+----------+-----+---------------+--------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b38dd09-f1f7-4c6c-a4d5-ec6d6be72489",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Dynamic Pricing",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e04d14e8-a36b-46db-bc6a-11fa66990299",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Count rows in each column where NULLs present| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "852620be-501c-40fa-817a-69ef03612d82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "840fd347-19ac-4cea-8a26-6c922bb2d6be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, \"Arabinda\", 23),\n",
    "    (2, \"Shyam\", None),\n",
    "    (3, \"Raghu\", 56),\n",
    "    (4, None, 32),\n",
    "    (5, None, None),\n",
    "    (6, \"John\", None)\n",
    "]\n",
    "\n",
    "data_schema=['ID','Name','Age']\n",
    "\n",
    "df=spark.createDataFrame(data,data_schema)\n",
    "\n",
    "#Approach-1\n",
    "df1=df.select([(df.count()-count(i)).alias(i) for i in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a421b220-674b-43fc-b9f0-9fd2c7cb93f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+\n| ID|    Name| Age|\n+---+--------+----+\n|  1|Arabinda|  23|\n|  2|   Shyam|null|\n|  3|   Raghu|  56|\n|  4|    null|  32|\n|  5|    null|null|\n|  6|    John|null|\n+---+--------+----+\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb564297-fa93-41e1-b3b6-08f552959cbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n| ID|Name|Age|\n+---+----+---+\n|  0|   2|  3|\n+---+----+---+\n\n"
     ]
    }
   ],
   "source": [
    "#Approach-2\n",
    "\n",
    "\n",
    "# Count null values for each column\n",
    "null_counts = [count(col(c)).alias(c) for c in df.columns]\n",
    "\n",
    "\n",
    "# Calculate the difference between total count and null count for each column\n",
    "df_null_counts = df.select([(df.count() - null_counts[i]).alias(df.columns[i]) for i in range(len(df.columns))])\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_null_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bfeafbe-d354-471f-a56c-a181fd9ea7c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n| ID|Name|Age|\n+---+----+---+\n|  0|   2|  3|\n+---+----+---+\n\n"
     ]
    }
   ],
   "source": [
    "#Appraoch-3\n",
    "df_null_=df.select ([count(when(col(i).isNull(), i)).alias(i) for i in df.columns])\n",
    "df_null_.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "799d8a0b-f15f-4c30-8fb4-18b0695bf56b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b3fd46e-b178-44f6-bd58-27aabdc729dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Count rows in each column where NULLs present",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

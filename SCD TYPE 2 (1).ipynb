{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac19b255-a194-4166-b614-bf06e3572521",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+----------+----------+----------+\n| ID|Product|Price|start_date|  end_date|is_current|\n+---+-------+-----+----------+----------+----------+\n|  1|      A|   60|2024-01-14|2024-02-17|         0|\n|  1|      A|   12|2024-02-18|2024-02-27|         0|\n|  1|      A| 2000|2024-02-28|      null|         1|\n|  2|      B|   34|2024-04-17|      null|         1|\n|  3|      C|   35|2024-04-09|      null|         1|\n|  4|      D|   67|2024-04-15|      null|         1|\n| 10|      Z|  109|2023-12-25|      null|         1|\n| 11|      U|  101|2024-02-28|      null|         1|\n+---+-------+-----+----------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, lag, lead\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SCDType2Example\").getOrCreate()\n",
    "\n",
    "# Sample data for source-1-df\n",
    "data1 = [\n",
    "    (1, 'A', '2024-01-14', 60),\n",
    "    (2, 'B', '2024-04-17', 34),\n",
    "    (3, 'C', '2024-04-09', 35),\n",
    "    (4, 'D', '2024-04-15', 67),\n",
    "    (10, 'Z', '2023-12-25', 109)\n",
    "]\n",
    "\n",
    "# Sample data for source-2-df\n",
    "data2 = [\n",
    "    (11, 'U', '2024-02-28', 101),\n",
    "    (1, 'A', '2024-02-28', 2000),\n",
    "    (1, 'A', '2024-02-18', 12)\n",
    "]\n",
    "\n",
    "# Create DataFrames\n",
    "df1 = spark.createDataFrame(data1, ['ID', 'Product', 'Transaction_date', 'Price'])\n",
    "df2 = spark.createDataFrame(data2, ['ID', 'Product', 'Transaction_date', 'Price'])\n",
    "\n",
    "# Convert Transaction_date to DateType\n",
    "df1 = df1.withColumn(\"Transaction_date\", col(\"Transaction_date\").cast(\"date\"))\n",
    "df2 = df2.withColumn(\"Transaction_date\", col(\"Transaction_date\").cast(\"date\"))\n",
    "\n",
    "# Combine DataFrames\n",
    "df_combined = df1.union(df2)\n",
    "\n",
    "# Create a window specification\n",
    "window_spec = Window.partitionBy(\"ID\", \"Product\").orderBy(col(\"Transaction_date\"))\n",
    "\n",
    "# Add row number to identify the latest record\n",
    "df_combined = df_combined.withColumn(\"row_num\", row_number().over(window_spec))\n",
    "\n",
    "# Add lead and lag to get the previous and next transaction dates\n",
    "df_combined = df_combined.withColumn(\"prev_date\", lag(\"Transaction_date\").over(window_spec))\n",
    "df_combined = df_combined.withColumn(\"next_date\", lead(\"Transaction_date\").over(window_spec))\n",
    "\n",
    "# Identify the active and historical records\n",
    "df_combined = df_combined.withColumn(\"is_current\", when(col(\"next_date\").isNull(), lit(1)).otherwise(lit(0)))\n",
    "\n",
    "# Create start_date and end_date for the records\n",
    "df_combined = df_combined.withColumn(\"start_date\", col(\"Transaction_date\"))\n",
    "df_combined = df_combined.withColumn(\"end_date\", when(col(\"is_current\") == 1, lit(None)).otherwise(col(\"next_date\") - 1))\n",
    "\n",
    "# Select the required columns\n",
    "result_df = df_combined.select(\"ID\", \"Product\", \"Price\", \"start_date\", \"end_date\", \"is_current\")\n",
    "\n",
    "# Show the result\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45291f54-87b3-468d-af7a-0bf4afd4540d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SCD TYPE 2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

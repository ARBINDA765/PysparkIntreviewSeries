{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38dc1d2a-2eb7-497b-9aef-8fe2112f11ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+-------------+\n|   name|job_satisfaction|      country|\n+-------+----------------+-------------+\n|   Alex|               4|          USA|\n|Saurabh|               5|           US|\n|   Mark|               4|United States|\n|  Shane|               4|          USA|\n|    Kim|               5|United States|\n|    Joe|               5|          USA|\n|   Mira|               5|United States|\n|   John|               3|          USA|\n|   Jane|               4|United States|\n|    Sam|               3|           US|\n|   Sara|               4|          USA|\n|   Luis|               5|United States|\n| Carlos|               4|           US|\n|   Anna|               3|          USA|\n|  Maria|               5|United States|\n+-------+----------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder.appName(\"SurveyData\").getOrCreate()\n",
    "\n",
    "# Define the data\n",
    "data = [\n",
    "    (\"Alex\", 4, \"USA\"),\n",
    "    (\"Saurabh\", 5, \"US\"),\n",
    "    (\"Mark\", 4, \"United States\"),\n",
    "    (\"Shane\", 4, \"USA\"),\n",
    "    (\"Kim\", 5, \"United States\"),\n",
    "    (\"Joe\", 5, \"USA\"),\n",
    "    (\"Mira\", 5, \"United States\"),\n",
    "    (\"John\", 3, \"USA\"),\n",
    "    (\"Jane\", 4, \"United States\"),\n",
    "    (\"Sam\", 3, \"US\"),\n",
    "    (\"Sara\", 4, \"USA\"),\n",
    "    (\"Luis\", 5, \"United States\"),\n",
    "    (\"Carlos\", 4, \"US\"),\n",
    "    (\"Anna\", 3, \"USA\"),\n",
    "    (\"Maria\", 5, \"United States\"),\n",
    "]\n",
    "\n",
    "# Define the schema\n",
    "columns = [\"name\", \"job_satisfaction\", \"country\"]\n",
    "\n",
    "# Create the DataFrame\n",
    "survey_df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "# Show the DataFrame\n",
    "survey_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6f522ea-f4a8-400b-8a20-27eec133e05f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------+\n|job_satisfaction|      country|total_response|\n+----------------+-------------+--------------+\n|               3|          USA|             3|\n|               4|          USA|             6|\n|               5|United States|             6|\n+----------------+-------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create the CTE equivalent by aggregating the survey data\n",
    "cte_survey = survey_df.groupBy(\"job_satisfaction\", \"country\") \\\n",
    "    .agg(count(\"*\").alias(\"number_of_respondents\"))\n",
    "\n",
    "# Step 2: Add the total_response and max_response columns using window functions\n",
    "window_spec = Window.partitionBy(\"job_satisfaction\")\n",
    "\n",
    "survey_with_responses = cte_survey.withColumn(\n",
    "    \"total_response\", sum(\"number_of_respondents\").over(window_spec)\n",
    ").withColumn(\n",
    "    \"max_response\", max(\"number_of_respondents\").over(window_spec)\n",
    ")\n",
    "\n",
    "# Step 3: Filter rows where max_response equals number_of_respondents\n",
    "result_df = survey_with_responses.filter(\n",
    "    col(\"max_response\") == col(\"number_of_respondents\")\n",
    ").select(\n",
    "    \"job_satisfaction\", \"country\", \"total_response\"\n",
    ").orderBy(\"number_of_respondents\")\n",
    "\n",
    "# Show the final result\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0032209-ba9d-4074-b308-dd24bc6f14e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "22 - The United States of America",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

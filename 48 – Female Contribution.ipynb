{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0223c314-ebbb-49e2-882c-c7a184eaef6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You are given a history of credit card transaction data for the people of India across cities. Write an SQL to find percentage contribution of spends by females in each city.  Round the percentage to 2 decimal places. Display city, total spend , female spend and female contribution in ascending order of city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fad252b-eb55-457b-be2a-e21a1c3b68e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"TransactionData\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"transaction_id\", IntegerType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"transaction_date\", StringType(), True),\n",
    "    StructField(\"card_type\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"amount\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "# Data\n",
    "data = [\n",
    "    (1, \"Delhi\", \"2024-01-13\", \"Gold\", \"F\", 500),\n",
    "    (2, \"Bengaluru\", \"2024-01-13\", \"Silver\", \"M\", 1000),\n",
    "    (3, \"Mumbai\", \"2024-01-14\", \"Silver\", \"F\", 1200),\n",
    "    (4, \"Bengaluru\", \"2024-01-14\", \"Gold\", \"M\", 900),\n",
    "    (5, \"Bengaluru\", \"2024-01-14\", \"Gold\", \"F\", 300),\n",
    "    (6, \"Delhi\", \"2024-01-15\", \"Silver\", \"M\", 200),\n",
    "    (7, \"Mumbai\", \"2024-01-15\", \"Gold\", \"F\", 900),\n",
    "    (8, \"Delhi\", \"2024-01-15\", \"Gold\", \"F\", 800),\n",
    "    (9, \"Mumbai\", \"2024-01-15\", \"Silver\", \"F\", 150),\n",
    "    (10, \"Mumbai\", \"2024-01-16\", \"Platinum\", \"F\", 1900),\n",
    "    (11, \"Bengaluru\", \"2024-01-16\", \"Platinum\", \"M\", 1250),\n",
    "    (12, \"Delhi\", \"2024-01-16\", \"Platinum\", \"F\", 130)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "#sum of total spend & converting the transaction_date to date datatype\n",
    "window_spec=Window.partitionBy(col(\"city\"))\n",
    "df=df.withColumn(\"transaction_date\",to_date(col(\"transaction_date\"),'yyyy-MM-dd')) \\\n",
    "    .withColumn(\"total_spend\",sum(\"amount\").over(window_spec)) \\\n",
    "        .withColumn(\"female_spent\",when(col(\"gender\")=='F',col(\"amount\")).otherwise(0))\n",
    "\n",
    "#renaming \n",
    "#percentage calculating\n",
    "#rounding & formating\n",
    "df=df.groupBy(col(\"city\")).agg(max(col(\"total_spend\")),sum(col(\"female_spent\"))) \\\n",
    "    .withColumnRenamed(\"max(total_spend)\",\"total_spend\") \\\n",
    "        .withColumnRenamed(\"sum(female_spent)\",\"female_spend\") \\\n",
    "            .withColumn(\"percentage\",(col(\"female_spend\")/col(\"total_spend\")*100)) \\\n",
    "                .withColumn(\"percentage\",round(col(\"percentage\"),2)) \\\n",
    "                    .withColumn(\"percentage\",format_number(col(\"percentage\"),2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf7d7a22-d138-4b5b-9a51-03d6be767557",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+----------+\n|     city|total_spend|female_spend|percentage|\n+---------+-----------+------------+----------+\n|Bengaluru|       3450|         300|      8.70|\n|    Delhi|       1630|        1430|     87.73|\n|   Mumbai|       4150|        4150|    100.00|\n+---------+-----------+------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5484a43b-7397-4212-93f7-33a5267db2f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "48 â€“ Female Contribution",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

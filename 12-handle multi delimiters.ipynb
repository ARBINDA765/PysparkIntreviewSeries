{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "295d0ea3-7dc1-4254-8913-ce136e3562be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Handle How to delimeter | inside the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6255c2ae-1598-4712-b013-eceb64b885a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+--------+\n| ID|    Name|Age|   Marks|\n+---+--------+---+--------+\n|  1|Arabinda| 23|32|49|39|\n|  2|   Shyam| 34|32|90|31|\n|  3|   Raghu| 42|30|98|43|\n|  4|    John| 27|43|87|56|\n|  5|      Su| 29|65|76|29|\n|  6|Manderic| 36|89|45|90|\n+---+--------+---+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Create DataFrame and Insert Data\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define schema for DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), False),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Marks\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Define data\n",
    "data = [\n",
    "    (1, \"Arabinda\", 23, \"32|49|39\"),\n",
    "    (2, \"Shyam\", 34, \"32|90|31\"),\n",
    "    (3, \"Raghu\", 42, \"30|98|43\"),\n",
    "    (4, \"John\", 27, \"43|87|56\"),\n",
    "    (5, \"Su\", 29, \"65|76|29\"),\n",
    "    (6, \"Manderic\", 36, \"89|45|90\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Split Marks column into an array of integers\n",
    "#df = df.withColumn(\"Marks\", split(df[\"Marks\"], \"\\|\").cast(ArrayType(IntegerType())))\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "366b497f-b464-4cfd-8317-a1fd764d0c74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Approach-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0263f035-5daf-4675-b7bd-3333153db05c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+---+----+----+\n| ID|    Name|Age|Phy|Chem|Math|\n+---+--------+---+---+----+----+\n|  1|Arabinda| 23| 32|  49|  39|\n|  2|   Shyam| 34| 32|  90|  31|\n|  3|   Raghu| 42| 30|  98|  43|\n|  4|    John| 27| 43|  87|  56|\n|  5|      Su| 29| 65|  76|  29|\n|  6|Manderic| 36| 89|  45|  90|\n+---+--------+---+---+----+----+\n\n"
     ]
    }
   ],
   "source": [
    "df_req1=df.withColumn(\"Phy\",split(df[\"Marks\"],\"\\|\")[0])\\\n",
    ".withColumn(\"Chem\",split(df[\"Marks\"],\"\\|\")[1])\\\n",
    ".withColumn(\"Math\",split(df[\"Marks\"],\"\\|\")[2]).drop(col(\"Marks\"))\n",
    "df_req1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6e23fc0-e2f8-40e7-a4d4-304b8e6226b2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Dynamically create the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f2cf61a-d2a4-495a-9240-4854c070286b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+---+----+----+\n| ID|    Name|Age|Phy|Chem|Math|\n+---+--------+---+---+----+----+\n|  1|Arabinda| 23| 32|  49|  39|\n|  2|   Shyam| 34| 32|  90|  31|\n|  3|   Raghu| 42| 30|  98|  43|\n|  4|    John| 27| 43|  87|  56|\n|  5|      Su| 29| 65|  76|  29|\n|  6|Manderic| 36| 89|  45|  90|\n+---+--------+---+---+----+----+\n\n"
     ]
    }
   ],
   "source": [
    "# Split the Marks column into an array\n",
    "df_split = df.withColumn(\"Marks\", split(df[\"Marks\"], \"\\|\"))\n",
    "\n",
    "# Determine the number of subjects\n",
    "num_subjects = len(df_split.select(\"Marks\").take(1)[0][0])\n",
    "\n",
    "# Generate column names\n",
    "#column_names = [\"Subject_\" + str(i+1) for i in range(num_subjects)]\n",
    "column_list = [\"Phy\", \"Chem\", \"Math\"]\n",
    "\n",
    "# Dynamically create new columns using vectorized operations\n",
    "for i, col_name in enumerate(column_list):\n",
    "    df_split = df_split.withColumn(col_name, df_split[\"Marks\"].getItem(i).cast(IntegerType()))\n",
    " \n",
    "\n",
    "# Drop the original Marks column\n",
    "df_final = df_split.drop(\"Marks\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_final.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24925515-6f5a-4913-afd6-366271137c10",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's break down the line df_split.select(\"Marks\").take(1)[0][0]:\n",
    "\n",
    "df_split.select(\"Marks\"): This part of the line selects the column named \"Marks\" from the DataFrame df_split. It returns a new DataFrame containing only the selected column.\n",
    ".take(1): This part of the line retrieves the first row from the DataFrame. The take() function is used to return a list of rows, and take(1) is used here to retrieve only the first row.\n",
    "\n",
    "[0]: This part of the line accesses the first element of the list returned by take(1). Since take(1) returns a list containing only one element (the first row), accessing [0] retrieves that first element.\n",
    "\n",
    "[0] (second occurrence): This part of the line accesses the first (and only) column value from the first row of the DataFrame. Since the previous step [0] returned the first row, accessing [0] again retrieves the value of the first column in that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "117b4baf-f54a-4e1c-a675-ff5321cd8689",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "handle multi delimiters",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

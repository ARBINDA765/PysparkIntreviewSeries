{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21e36974-f00b-464c-82c8-8e2900365d63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A hotel has accidentally made overbookings for certain rooms on specific dates. Due to this error, some rooms have been assigned to multiple customers for overlapping periods, leading to potential conflicts. The hotel management needs to rectify this mistake by contacting the affected customers and providing them with alternative arrangements.\n",
    "\n",
    " \n",
    "\n",
    "Your task is to write an SQL query to identify the overlapping bookings for each room and determine the list of customers affected by these overlaps. For each room and overlapping date, the query should list the customers who have booked the room for that date. \n",
    " \n",
    "\n",
    "A booking's check-out date is not inclusive, meaning that if a room is booked from April 1st to April 4th, it is considered occupied from April 1st to April 3rd , another customer can check-in on April 4th and that will not be considered as overlap.\n",
    " \n",
    "\n",
    "Order the result by room id, booking date. You may use calendar dim table which has all the dates for the year April 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1de2bb6-cf62-4562-bc3d-96d5bfa1e134",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+--------------+\n|room_id|customer_id|check_in_date|check_out_date|\n+-------+-----------+-------------+--------------+\n|      1|        101|   2024-04-01|    2024-04-04|\n|      2|        102|   2024-04-02|    2024-04-05|\n|      1|        103|   2024-04-02|    2024-04-06|\n|      3|        104|   2024-04-03|    2024-04-05|\n|      2|        105|   2024-04-04|    2024-04-07|\n|      1|        106|   2024-04-05|    2024-04-08|\n|      3|        107|   2024-04-05|    2024-04-09|\n+-------+-----------+-------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"CreateBookingsTable\").getOrCreate()\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"room_id\", IntegerType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"check_in_date\", StringType(), True),\n",
    "    StructField(\"check_out_date\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create the data\n",
    "data = [\n",
    "    (1, 101, \"2024-04-01\", \"2024-04-04\"),\n",
    "    (2, 102, \"2024-04-02\", \"2024-04-05\"),\n",
    "    (1, 103, \"2024-04-02\", \"2024-04-06\"),\n",
    "    (3, 104, \"2024-04-03\", \"2024-04-05\"),\n",
    "    (2, 105, \"2024-04-04\", \"2024-04-07\"),\n",
    "    (1, 106, \"2024-04-05\", \"2024-04-08\"),\n",
    "    (3, 107, \"2024-04-05\", \"2024-04-09\")\n",
    "]\n",
    "\n",
    "# Create the DataFrame\n",
    "bookings = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Show the DataFrame\n",
    "bookings.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28ce8053-eaf9-45c9-bdb7-66317190028b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Generating the calender table\n",
    "\n",
    "start_date=datetime(2024,4,1)\n",
    "end_date=datetime(2024,4,30)\n",
    "\n",
    "date_list=[(start_date+timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range((end_date-start_date).days+1)]\n",
    "\n",
    "data=[(date,) for date in date_list]\n",
    "schema_cal=StructType([\n",
    "    StructField(\"cal_date\",StringType(),True)\n",
    "    ])\n",
    "calendar_dim=spark.createDataFrame(data,schema=schema_cal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d63463e-7060-48e0-b8e1-29d670eab06f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+--------+\n|room_id| book_date|customers|counting|\n+-------+----------+---------+--------+\n|      1|2024-04-02|  101,103|       2|\n|      1|2024-04-03|  101,103|       2|\n|      1|2024-04-05|  103,106|       2|\n|      2|2024-04-04|  102,105|       2|\n+-------+----------+---------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, collect_list, concat_ws, count\n",
    "\n",
    "# Step 1: Create the CTE equivalent (joining bookings and calendar_dim)\n",
    "cte = bookings.join(calendar_dim, \n",
    "                    (calendar_dim.cal_date >= bookings.check_in_date) & \n",
    "                    (calendar_dim.cal_date < bookings.check_out_date)) \\\n",
    "              .select(col(\"room_id\"), col(\"customer_id\"), col(\"cal_date\").alias(\"book_date\"))\n",
    "\n",
    "# Step 2: Group by room_id and book_date, aggregate customer IDs\n",
    "result_df = cte.groupBy(col(\"room_id\"), col(\"book_date\")) \\\n",
    "    .agg(\n",
    "        concat_ws(\",\", collect_list(col(\"customer_id\"))).alias(\"customers\"),  # Comma-separated customer IDs\n",
    "        count(\"*\").alias(\"counting\")  # Count the number of rows in each group\n",
    "    ) \\\n",
    "        .filter(col(\"counting\") > 1) \\\n",
    "            .orderBy(col(\"room_id\"), col(\"book_date\"))  # Order by room_id and book_date\n",
    "\n",
    "# Step 3: Show the result\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9b3ef3e-83cf-40ff-919c-db4c71bc07b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "78 - Hotel Booking Mistake",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
